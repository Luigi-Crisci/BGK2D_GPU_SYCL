{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.transforms as mtrans\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "hw = [\"NVIDIA\", \"AMD\", \"INTEL\"]\n",
    "precision = [\"SINGLE\", \"DOUBLE\"]\n",
    "use_case = [\"LDC\", \"VKS\"]\n",
    "compilers = [\"dpcpp\", \"AdaptiveCpp\"]\n",
    "sycl_ranges = [\"range\", \"ndrange\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "sns.set_theme()\n",
    "\n",
    "\n",
    "res = pd.read_csv(\"results.csv\")\n",
    "res = res.loc[(res[\"precision\"] != \"MIXED1\" ) & (res[\"precision\"] != \"MIXED2\")]\n",
    "#find best fortran implementation for each hw\n",
    "best_impl = dict()\n",
    "for u in use_case:\n",
    "    best_impl[u] = dict()\n",
    "    for h in hw:\n",
    "        best_impl[u][h] = dict()\n",
    "        for p in precision:\n",
    "            filtered_df = res[((res[\"hw\"] == h) & (res[\"usecase\"] == u) & (res[\"impl\"] == \"fortran\") & (res[\"precision\"] == p))].sort_values(by=\"mlups\").reset_index(drop=True)\n",
    "            if not filtered_df.empty:\n",
    "                first_mlups_value = filtered_df[\"mlups\"].iloc[0]\n",
    "                # Optionally, store the value in best_impl dictionary\n",
    "                best_impl[u][h][p] = first_mlups_value\n",
    "            else:\n",
    "                best_impl[u][h][p] = None\n",
    "    \n",
    "print(best_impl)\n",
    "\n",
    "# Get sycl values\n",
    "sycl_csv = res[(res[\"impl\"] == \"sycl\")]\n",
    "# Divide sycl values by best fortran values\n",
    "for u in use_case:\n",
    "    for h in hw:\n",
    "        for p in precision:\n",
    "            rows = sycl_csv.loc[(sycl_csv[\"hw\"] == h) & (sycl_csv[\"usecase\"] == u) & (sycl_csv[\"precision\"] == p)]\n",
    "            if not rows.empty:\n",
    "                sycl_csv.loc[(sycl_csv[\"hw\"] == h) & (sycl_csv[\"usecase\"] == u) & (sycl_csv[\"precision\"] == p), \"mlups\"] = sycl_csv.loc[(sycl_csv[\"hw\"] == h) & (sycl_csv[\"usecase\"] == u) & (sycl_csv[\"precision\"] == p), \"mlups\"].map(lambda x: x / best_impl[u][h][p]) \n",
    "\n",
    "\n",
    "for u in use_case:\n",
    "    for h in hw:\n",
    "        for p in precision:\n",
    "            for c in compilers:\n",
    "                rows = sycl_csv.loc[(sycl_csv[\"hw\"] == h) & (sycl_csv[\"usecase\"] == u) & (sycl_csv[\"precision\"] == p) & (sycl_csv[\"parallelism\"] == c)]\n",
    "                if not rows.empty:\n",
    "                    # Drop all rows except the the one with the hightest mlups\n",
    "                    rows.sort_values(by=\"mlups\", inplace=True)\n",
    "                    sycl_csv.drop(rows.index[0:-1], inplace=True)\n",
    "for u in use_case:\n",
    "    for h in hw:\n",
    "            rows = sycl_csv.loc[(sycl_csv[\"hw\"] == h) & (sycl_csv[\"usecase\"] == u)]\n",
    "            print(f\"{u} - {h} -> {rows['mlups'].mean()}\")\n",
    "            \n",
    "        \n",
    "#subsitute each \"dpcpp\" entry in column \"compilers\" to \"Intel DPC++\"\n",
    "sycl_csv[\"parallelism\"] = sycl_csv[\"parallelism\"].str.replace(\"dpcpp\", \"Intel DPC++\")\n",
    "\n",
    "parallelisms = [\"AdaptiveCpp\", \"Intel DPC++\"]\n",
    "total_plots = len(hw) * len(parallelisms)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=total_plots, figsize=(total_plots * 5, 5), sharey=True)\n",
    "color_palette = sns.color_palette(\"viridis\", len(precision))\n",
    "color_map = dict(zip(precision, color_palette))\n",
    "\n",
    "plot_index = 0\n",
    "for parallelism in parallelisms:\n",
    "    for h in hw:\n",
    "        # Assuming 'use_case' and 'precision' are defined and 'res' is filtered accordingly\n",
    "        for k, u in enumerate(use_case):\n",
    "            for l, p in enumerate(precision):\n",
    "                df_filtered = sycl_csv[(sycl_csv[\"hw\"] == h) & (sycl_csv[\"usecase\"] == u) & (sycl_csv[\"precision\"] == p) & (sycl_csv[\"parallelism\"] == parallelism)]\n",
    "                if not df_filtered.empty:\n",
    "                    mean_mlups = df_filtered[\"mlups\"].mean()\n",
    "                    ax = axes[plot_index]\n",
    "                    ax.bar(k + l*0.2, mean_mlups, color=color_map[p], width=0.2, label=f'{p}' if plot_index == 0 else \"\")\n",
    "                    # Modify the ax.bar to have just one hue for the precision\n",
    "                    ax.set_title(f'{h}', y = -0.2)\n",
    "                    if plot_index == 1 or plot_index == 4:\n",
    "                        ax.set_xlabel(f'{parallelism}')\n",
    "                        # move it to the top\n",
    "                        ax.xaxis.set_label_position('top')\n",
    "                    ax.axhline(1, color='red', linewidth=3, linestyle='--')\n",
    "                    ax.set_xticks(range(len(use_case)))\n",
    "                    ax.set_xticklabels(use_case),\n",
    "                    # set hatch\n",
    "                    if parallelism == \"AdaptiveCpp\":\n",
    "                        # iterate over bars\n",
    "                        for bar in ax.patches:\n",
    "                            # set hatching\n",
    "                            bar.set_hatch('/')\n",
    "                            # set hatch color\n",
    "                            bar.set_edgecolor('black')\n",
    "                    else:\n",
    "                        # iterate over bars\n",
    "                        for bar in ax.patches:\n",
    "                            # set hatching\n",
    "                            bar.set_hatch('x')\n",
    "                            # set hatch color\n",
    "                            bar.set_edgecolor('black')\n",
    "                    if plot_index == 0:\n",
    "                        ax.set_ylabel('Speedup')\n",
    "                    trans = mtrans.Affine2D().translate(6, 0)\n",
    "                    for t in ax.get_xticklabels():\n",
    "                        t.set_transform(t.get_transform()+trans)\n",
    "                    # Increase all subplots font size\n",
    "                    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "                                ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "                        item.set_fontsize(23)\n",
    "                        \n",
    "        plot_index += 1\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "legend_handles = [mpatches.Patch(color=color_map[p], label=p) for p in precision]\n",
    "\n",
    "fig.legend(handles=legend_handles, title='Precision', loc='upper center', ncol=4, fontsize=20, title_fontsize=20, bbox_to_anchor=(0.5, 1.15))\n",
    "# g.fig.suptitle('Bar Plot with Two Groups by Type', y=1.03) # Adjust title and its position\n",
    "# g.set_axis_labels('Category', 'Value') # Set x and y axis labels\n",
    "plt.savefig(\"plots/speedup.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "sycl_csv = res[(res[\"impl\"] == \"sycl\")]\n",
    "for u in use_case:\n",
    "    for h in hw:\n",
    "        for p in precision:\n",
    "            for c in compilers:\n",
    "                rows = sycl_csv.loc[(sycl_csv[\"hw\"] == h) & (sycl_csv[\"usecase\"] == u) & (sycl_csv[\"precision\"] == p) & (sycl_csv[\"parallelism\"] == c)]\n",
    "                if not rows.empty:\n",
    "                    # Drop all rows except the the one with the hightest mlups\n",
    "                    rows.sort_values(by=\"mlups\", inplace=True)\n",
    "                    sycl_csv.drop(rows.index[0:-1], inplace=True)\n",
    "                    \n",
    "#subsitute each \"dpcpp\" entry in column \"compilers\" to \"Intel DPC++\"\n",
    "sycl_csv[\"parallelism\"] = sycl_csv[\"parallelism\"].str.replace(\"dpcpp\", \"Intel DPC++\")\n",
    "\n",
    "parallelisms = [\"AdaptiveCpp\", \"Intel DPC++\"]\n",
    "total_plots = len(hw) * len(parallelisms)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=total_plots, figsize=(total_plots * 5, 5), sharey=True)\n",
    "color_palette = sns.color_palette(\"viridis\", len(precision))\n",
    "color_map = dict(zip(precision, color_palette))\n",
    "\n",
    "plot_index = 0\n",
    "for parallelism in parallelisms:\n",
    "    for h in hw:\n",
    "        # Assuming 'use_case' and 'precision' are defined and 'res' is filtered accordingly\n",
    "        for k, u in enumerate(use_case):\n",
    "            for l, p in enumerate(precision):\n",
    "                df_filtered = sycl_csv[(sycl_csv[\"hw\"] == h) & (sycl_csv[\"usecase\"] == u) & (sycl_csv[\"precision\"] == p) & (sycl_csv[\"parallelism\"] == parallelism)]\n",
    "                if not df_filtered.empty:\n",
    "                    mean_mlups = df_filtered[\"mlups\"].mean()\n",
    "                    ax = axes[plot_index]\n",
    "                    ax.bar(k + l*0.2, mean_mlups, color=color_map[p], width=0.2, label=f'{p}' if plot_index == 0 else \"\")\n",
    "                    # Modify the ax.bar to have just one hue for the precision\n",
    "                    ax.set_title(f'{h}', y = -0.2)\n",
    "                    if plot_index == 1 or plot_index == 4:\n",
    "                        ax.set_xlabel(f'{parallelism}')\n",
    "                        ax.xaxis.set_label_position('top')\n",
    "                    ax.set_xticks(range(len(use_case)))\n",
    "                    ax.set_xticklabels(use_case),\n",
    "                    # set hatch\n",
    "                    if parallelism == \"AdaptiveCpp\":\n",
    "                        # iterate over bars\n",
    "                        for bar in ax.patches:\n",
    "                            # set hatching\n",
    "                            bar.set_hatch('/')\n",
    "                            # set hatch color\n",
    "                            bar.set_edgecolor('black')\n",
    "                    else:\n",
    "                        # iterate over bars\n",
    "                        for bar in ax.patches:\n",
    "                            # set hatching\n",
    "                            bar.set_hatch('x')\n",
    "                            # set hatch color\n",
    "                            bar.set_edgecolor('black')\n",
    "                    if plot_index == 0:\n",
    "                        ax.set_ylabel('MLUP/s')\n",
    "                    trans = mtrans.Affine2D().translate(6, 0)\n",
    "                    for t in ax.get_xticklabels():\n",
    "                        t.set_transform(t.get_transform()+trans)\n",
    "                    # Increase all subplots font size\n",
    "                    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "                                ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "                        item.set_fontsize(23)\n",
    "                        \n",
    "        plot_index += 1\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "legend_handles = [mpatches.Patch(color=color_map[p], label=p) for p in precision]\n",
    "\n",
    "fig.legend(handles=legend_handles, title='Precision', loc='upper center', ncol=4, fontsize=20, title_fontsize=20, bbox_to_anchor=(0.5, 1.15))\n",
    "# g.fig.suptitle('Bar Plot with Two Groups by Type', y=1.03) # Adjust title and its position\n",
    "# g.set_axis_labels('Category', 'Value') # Set x and y axis labels\n",
    "plt.savefig(\"plots/mlups.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "sycl_csv = res[(res[\"impl\"] == \"sycl\")] # Reset csv\n",
    "# add new coloumn to sycl_csv eith the combination of values in columns \"alloc_type\" and \"range\"\n",
    "sycl_csv[\"alloc_type_range\"] = sycl_csv[\"alloc_type\"] + \"\\n\" + sycl_csv[\"range\"]\n",
    "fortran_par_types = [\"doconcurrent\", \"openacc\", \"offload\"]         \n",
    "\n",
    "# duplcate each row three times and add the values in fortran_par_types to the new column \"fortran_par\"\n",
    "sycl_csv = sycl_csv.loc[sycl_csv.index.repeat(3)].reset_index(drop=True)\n",
    "sycl_csv[\"fortran_par\"] = fortran_par_types * int(len(sycl_csv) / 3)\n",
    "sycl_csv[\"speedup\"] = 0\n",
    "\n",
    "for h in hw:\n",
    "    for p in precision:\n",
    "        for u in use_case:\n",
    "            for fortran_par in fortran_par_types:\n",
    "#                 # print(f\"hw: {h}, precision: {p}, usecase: {u}, fortran_par: {fortran_par}\")\n",
    "                value = res[(res[\"impl\"] == \"fortran\") & (res[\"parallelism\"] == fortran_par) & (res[\"hw\"] == h) & (res[\"usecase\"] == u) & (res[\"precision\"] == p)].reset_index(drop=True)\n",
    "                if not value.empty:\n",
    "                    # value[\"mlups\"].iloc[0]\n",
    "                    subset = sycl_csv.loc[(sycl_csv[\"hw\"] == h) & (sycl_csv[\"usecase\"] == u) & (sycl_csv[\"precision\"] == p) & (sycl_csv[\"fortran_par\"] == fortran_par)]\n",
    "                    subset[\"speedup\"] = subset[\"mlups\"] / value[\"mlups\"].iloc[0]\n",
    "                    sycl_csv.update(subset)\n",
    "                # elif h == \"INTEL\" and fortran_par == \"doconcurrent\":\n",
    "                #     subset = sycl_csv.loc[(sycl_csv[\"hw\"] == h) & (sycl_csv[\"usecase\"] == u) & (sycl_csv[\"precision\"] == p) & (sycl_csv[\"fortran_par\"] == fortran_par)]\n",
    "                #     subset[\"speedup\"] = np.max(subset[\"speedup\"])\n",
    "                #     sycl_csv.update(subset)\n",
    "\n",
    "for p in precision:\n",
    "    for u in use_case:\n",
    "        # get all value with hw intel, precision p, usecase u\n",
    "        sycl_csv_tmp = sycl_csv[(sycl_csv[\"hw\"] == \"INTEL\") & (sycl_csv[\"precision\"] == p) & (sycl_csv[\"usecase\"] == u)]\n",
    "        max_idx = sycl_csv_tmp[\"speedup\"].idxmax()\n",
    "        max_value = sycl_csv_tmp.loc[max_idx, \"speedup\"]\n",
    "        subset = sycl_csv.loc[(sycl_csv[\"hw\"] == \"INTEL\") & (sycl_csv[\"precision\"] == p) & (sycl_csv[\"usecase\"] == u) & (sycl_csv[\"fortran_par\"] == \"doconcurrent\")]\n",
    "        subset[\"speedup\"] = max_value\n",
    "        sycl_csv.update(subset)\n",
    "\n",
    "        \n",
    "# # make seaborn heatmap\n",
    "# Filter only LDC use case\n",
    "sycl_csv = sycl_csv[sycl_csv[\"usecase\"] == \"LDC\"]\n",
    "beaufity_precision = dict(\n",
    "    SINGLE=\"Single Precision\",\n",
    "    DOUBLE=\"Double Precision\",\n",
    "    MIXED1=\"Mixed Precision 1\",\n",
    "    MIXED2=\"Mixed Precision 2\"\n",
    ")\n",
    "\n",
    "# renane each \"doconcurrent\" entry from column \"fortran_par\" to \"DC\"\n",
    "sycl_csv[\"fortran_par\"] = sycl_csv[\"fortran_par\"].str.replace(\"doconcurrent\", \"DC\")\n",
    "\n",
    "for h in hw:\n",
    "    for compiler in compilers:\n",
    "        sycl_csv_tmp = sycl_csv[(sycl_csv[\"hw\"] == h) & (sycl_csv[\"parallelism\"] == compiler)]\n",
    "        # ax = sns.catplot(kind=\"bar\", x='fortran_par', y='speedup', hue='alloc_type_range', col=\"precision\", data=sycl_csv_tmp)\n",
    "        # ax.set_titles('{col_name}')\n",
    "        # ax.set_axis_labels('Fortran Parallelism', 'Speedup')\n",
    "        # ax.fig.suptitle(f'{h} - {compiler}')\n",
    "        # plt.show()\n",
    "        # sycl_csv_tmp.to_csv(f\"{h}_{compiler}.csv\", index=False)\n",
    "        for p in [\"MIXED1\", \"MIXED2\"]:\n",
    "            sycl_csv_tmp_2 = sycl_csv_tmp[sycl_csv_tmp[\"precision\"] == p]\n",
    "            agg_sycl_csv = sycl_csv_tmp_2.groupby(['alloc_type_range', 'fortran_par'])['speedup'].mean().reset_index()\n",
    "\n",
    "            # Pivot the aggregated DataFrame\n",
    "            pivot_sycl_csv = agg_sycl_csv.pivot(index='alloc_type_range', columns='fortran_par', values='speedup')\n",
    "\n",
    "            # Plot the heatmap\n",
    "            # Define the colors for the colormap (red, yellow, green)\n",
    "            colors = [(0.7, 0, 0), (0.7, 0.7, 0), (0, 0.5, 0)]  # Example darker shades\n",
    "        # Create the colormap with darker colors\n",
    "            cmap = LinearSegmentedColormap.from_list(\"DarkRedYellowGreen\", colors)\n",
    "            # make a colormap for the heatmap that goes from red to yellow to green\n",
    "            \n",
    "            ax = sns.heatmap(data=pivot_sycl_csv, annot=True,fmt=\".1f\",cmap=cmap, linewidth=0.5)\n",
    "            ax.set_title(f'{beaufity_precision[p]}')\n",
    "            _xlabels = ax.get_xticklabels()\n",
    "            for labels in _xlabels:\n",
    "                labels.set(text=labels.get_text().replace(' ',\"\\n\"))\n",
    "            ax.set_xticklabels(_xlabels, rotation=-360, ha='center', rotation_mode='anchor')\n",
    "            ax.set_yticklabels(ax.get_yticklabels(), ha='center', x=-0.17, rotation=0)\n",
    "            ax.set(xlabel='',ylabel='')\n",
    "            # set the annotated values to be in the center of the cells\n",
    "            for t in ax.texts:\n",
    "                if h == \"INTEL\" and t.get_position()[0] == 0.5:\n",
    "                    # set the unicode symbol for infinity\n",
    "                    t.set_text(\"N.D.\")\n",
    "                    # t.set_text(\"Infinite\")\n",
    "                elif t.get_text() == \"0.0\":\n",
    "                        t.set_text(\"N.S.\")\n",
    "                else:\n",
    "                    t.set_text(t.get_text() + \"x\")\n",
    "                # Increase font size\n",
    "                t.set_fontsize(23)\n",
    "            if p == \"DOUBLE\" or p == \"MIXED2\":\n",
    "                # make the ytickslaels white\n",
    "                # ax.set_yticklabels(ax.get_yticklabels(), color='white')\n",
    "                ax.set_yticklabels([])\n",
    "            # Increase font size\n",
    "            for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "                        ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "                item.set_fontsize(23)\n",
    "            \n",
    "\n",
    "            plt.savefig(f\"plots/{h}_{compiler}_{p}.pdf\", bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "# ax = sns.heatmap(data = sycl_csv)\n",
    "\n",
    "\n",
    "# for fortran_par in fortran_par_types:\n",
    "#     value = res[(res[\"impl\"] == \"fortran\") & (res[\"parallelism\"] == fortran_par)]\n",
    "#     sycl_csv[fortran_par] = sycl_csv[\"mlups\"] / \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## barplot with speedup compared to offload\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "sycl_csv = res[(res[\"impl\"] == \"sycl\")] # Reset csv\n",
    "# add new coloumn to sycl_csv eith the combination of values in columns \"alloc_type\" and \"range\"\n",
    "sycl_csv[\"alloc_type_range\"] = sycl_csv[\"alloc_type\"] + \"\\n\" + sycl_csv[\"range\"]\n",
    "sycl_csv[\"speedup\"] = 0\n",
    "\n",
    "for h in hw:\n",
    "    for p in precision:\n",
    "        for u in use_case:\n",
    "#                 # print(f\"hw: {h}, precision: {p}, usecase: {u}, fortran_par: {fortran_par}\")\n",
    "            value = res[(res[\"impl\"] == \"fortran\") & (res[\"parallelism\"] == \"offload\") & (res[\"hw\"] == h) & (res[\"usecase\"] == u) & (res[\"precision\"] == p)].reset_index(drop=True)\n",
    "            if not value.empty:\n",
    "                # value[\"mlups\"].iloc[0]\n",
    "                subset = sycl_csv.loc[(sycl_csv[\"hw\"] == h) & (sycl_csv[\"usecase\"] == u) & (sycl_csv[\"precision\"] == p)]\n",
    "                subset[\"speedup\"] = subset[\"mlups\"] / value[\"mlups\"].iloc[0]\n",
    "                sycl_csv.update(subset)\n",
    "        \n",
    "# # make seaborn heatmap\n",
    "# Filter only LDC use case\n",
    "sycl_csv = sycl_csv[sycl_csv[\"usecase\"] == \"LDC\"]\n",
    "beaufity_precision = dict(\n",
    "    SINGLE=\"Single Precision\",\n",
    "    DOUBLE=\"Double Precision\",\n",
    "    MIXED1=\"Mixed Precision 1\",\n",
    "    MIXED2=\"Mixed Precision 2\"\n",
    ")\n",
    "\n",
    "# fig = sns.relplot(kind=\"scatter\", x='alloc_type_range', y='speedup', hue='hw', style='precision', col=\"parallelism\", data=sycl_csv, s=200)\n",
    "# Set hue color to red, blue, and green for NVIDIA, AMD, and INTEL respectively\n",
    "sycl_csv[\"parallelism\"] = sycl_csv[\"parallelism\"].str.replace(\"dpcpp\", \"Intel DPC++\")\n",
    "\n",
    "fig = sns.relplot(kind=\"scatter\", x='alloc_type_range', y='speedup', hue='hw', style='precision', col=\"parallelism\", data=sycl_csv, s=200, palette={'NVIDIA': 'Green', 'AMD': 'Brown', 'INTEL': 'Blue'})\n",
    "# add a red line at y=1\n",
    "fig.map(plt.axhline, y=1, color='red', linestyle='--')\n",
    "fig.set_titles('{col_name}')\n",
    "fig.set_xlabels(\"\")\n",
    "fig.set_ylabels(\"Speedup over FORTRAN Offload\")\n",
    "\n",
    "plt.savefig(\"plots/speedup_over_offload.pdf\", bbox_inches='tight')\n",
    "\n",
    "\n",
    "amd_mixed = sycl_csv.loc[(sycl_csv[\"hw\"] == \"AMD\") & (sycl_csv[\"precision\"] == \"MIXED1\")]\n",
    "dpcpp_range = sycl_csv.loc[(sycl_csv[\"parallelism\"] == \"Intel DPC++\") & (sycl_csv[\"range\"] == \"range\") & (sycl_csv[\"hw\"] == \"NVIDIA\")]\n",
    "sycl_csv_copy = sycl_csv.copy()\n",
    "sycl_csv_copy.drop(amd_mixed.index, inplace=True)\n",
    "sycl_csv_copy.drop(dpcpp_range.index, inplace=True)\n",
    "\n",
    "fig = sns.relplot(kind=\"scatter\", x='alloc_type_range', y='speedup', hue='hw', style='precision', col=\"parallelism\", data=sycl_csv_copy, s=200, palette={'NVIDIA': 'Green', 'AMD': 'Brown', 'INTEL': 'Blue'})\n",
    "# add a red line at y=1\n",
    "fig.map(plt.axhline, y=1, color='red', linestyle='--')\n",
    "fig.set_titles('{col_name}')\n",
    "fig.set_xlabels(\"\")\n",
    "fig.set_ylabels(\"Speedup over FORTRAN Offload\")\n",
    "\n",
    "plt.savefig(\"plots/speedup_over_offload_detail.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intel DPC++ range\n",
    "intel_csv = pd.read_csv(\"./results_INTEL_SYCL.csv\")\n",
    "\n",
    "# filter only LDC use case\n",
    "intel_csv_tmp = intel_csv[(intel_csv[\"usecase\"] == \"VKS\") & (intel_csv[\"alloc_type\"] == \"device\") ]\n",
    "for p in precision:\n",
    "    for r in [\"ndrange\", \"range\"]:\n",
    "        acpp_tmp = intel_csv_tmp[(intel_csv_tmp[\"precision\"] == p) & (intel_csv_tmp[\"range\"] == r) & (intel_csv_tmp[\"parallelism\"] == \"AdaptiveCpp\")]\n",
    "        dpcpp_tmp = intel_csv_tmp[(intel_csv_tmp[\"precision\"] == p) & (intel_csv_tmp[\"range\"] == r) & (intel_csv_tmp[\"parallelism\"] == \"dpcpp\")]\n",
    "        print(f\"Device - {p} - {r}: {acpp_tmp['mlups'].mean() / dpcpp_tmp['mlups'].mean()}\")\n",
    "print(\"\\n\")\n",
    "intel_csv_tmp = intel_csv[(intel_csv[\"usecase\"] == \"VKS\") & (intel_csv[\"alloc_type\"] == \"shared\") ]\n",
    "for p in precision:\n",
    "    for r in [\"ndrange\", \"range\"]:\n",
    "        acpp_tmp = intel_csv_tmp[(intel_csv_tmp[\"precision\"] == p) & (intel_csv_tmp[\"range\"] == r) & (intel_csv_tmp[\"parallelism\"] == \"AdaptiveCpp\")]\n",
    "        dpcpp_tmp = intel_csv_tmp[(intel_csv_tmp[\"precision\"] == p) & (intel_csv_tmp[\"range\"] == r) & (intel_csv_tmp[\"parallelism\"] == \"dpcpp\")]\n",
    "        print(f\"{p} - {r} - {acpp_tmp['mlups'].mean() / dpcpp_tmp['mlups'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMD \n",
    "amd_csv = pd.read_csv(\"results.csv\")\n",
    "\n",
    "# filter only LDC use case\n",
    "amd_csv_tmp = amd_csv[(amd_csv[\"usecase\"] == \"LDC\") & (amd_csv[\"alloc_type\"] == \"device\") & ((amd_csv[\"hw\"] == \"AMD\") | (amd_csv[\"hw\"] == \"NVIDIA\"))]\n",
    "for c in compilers:\n",
    "    for p in precision:\n",
    "        for r in [\"range\", \"ndrange\"]:\n",
    "            nvidia_tmp = amd_csv_tmp[(amd_csv_tmp[\"precision\"] == p) & (amd_csv_tmp[\"range\"] == r) & (amd_csv_tmp[\"parallelism\"] == c ) & (amd_csv_tmp[\"hw\"] == \"NVIDIA\")]\n",
    "            amd_tmp = amd_csv_tmp[(amd_csv_tmp[\"precision\"] == p) & (amd_csv_tmp[\"range\"] == r) & (amd_csv_tmp[\"parallelism\"] == c) & (amd_csv_tmp[\"hw\"] == \"AMD\")]\n",
    "            print(f\"Shared - {c} - {p} - {r}: {amd_tmp['mlups'].mean() / nvidia_tmp['mlups'].mean()}\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of entry in range and nd_range above or under the baseline\n",
    "# print(sycl_csv)\n",
    "sycl_csv[\"parallelism\"] = sycl_csv[\"parallelism\"].str.replace(\"Intel DPC++\", \"dpcpp\")\n",
    "\n",
    "above = dict()\n",
    "under = dict()\n",
    "for h in hw:\n",
    "    above[h] = dict()\n",
    "    under[h] = dict()\n",
    "    for c in compilers:\n",
    "        above[h][c] = dict()\n",
    "        under[h][c] = dict()\n",
    "        for alloc_type in [\"device\", \"shared\"]:\n",
    "            above[h][c][alloc_type] = dict()\n",
    "            under[h][c][alloc_type] = dict()\n",
    "            for r in sycl_ranges:\n",
    "                # print(f\"{h} - {c} - {alloc_type} - {r}\")\n",
    "                subset = sycl_csv[(sycl_csv[\"hw\"] == h) & (sycl_csv['range'] == r) & (sycl_csv[\"parallelism\"] == c) & (sycl_csv[\"alloc_type\"] == alloc_type)]\n",
    "                if not subset.empty:\n",
    "                    above[h][c][alloc_type][r] = len(subset[subset['speedup'] >= 1]) / len(subset) * 100\n",
    "                    under[h][c][alloc_type][r] = len(subset[subset['speedup'] < 1]) / len(subset) * 100\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"For each hardware how many times the SYCL results are above the baseline\")\n",
    "tmp_above = dict()\n",
    "tmp_under = dict()\n",
    "for h in hw:\n",
    "    tmp_above[h] = []\n",
    "    tmp_under[h] = []\n",
    "    for r in sycl_ranges:\n",
    "        for c in compilers:\n",
    "            for alloc_type in [\"device\", \"shared\"]:\n",
    "                    try:\n",
    "                        tmp_above[h].append(above[h][c][alloc_type][r])\n",
    "                        tmp_under[h].append(under[h][c][alloc_type][r])\n",
    "                    except:\n",
    "                        print(f\"{h} - {c} - {alloc_type} - {r}\")\n",
    "for h in hw:\n",
    "    print(f\"{h} - Above: {np.mean(tmp_above[h])}\")\n",
    "    print(f\"{h} - Under: {np.mean(tmp_under[h])}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"For each compiler how manu times is above the baseline\")\n",
    "tmp_above = dict()\n",
    "tmp_under = dict()\n",
    "for c in compilers:\n",
    "    tmp_above[c] = []\n",
    "    tmp_under[c] = []\n",
    "    for r in sycl_ranges:\n",
    "        for h in hw:\n",
    "            for alloc_type in [\"device\", \"shared\"]:\n",
    "                    try:\n",
    "                        tmp_above[c].append(above[h][c][alloc_type][r])\n",
    "                        tmp_under[c].append(under[h][c][alloc_type][r])\n",
    "                    except:\n",
    "                        pass\n",
    "for c in compilers:\n",
    "    print(f\"{c} - Above: {np.mean(tmp_above[c])}\")\n",
    "    print(f\"{c} - Under: {np.mean(tmp_under[c])}\")\n",
    "    \n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"For each compiler and range, how many times is above the baseline\")\n",
    "tmp_above = dict()\n",
    "tmp_under = dict()\n",
    "for c in compilers:\n",
    "    tmp_above[c] =  dict()\n",
    "    tmp_under[c] = dict()\n",
    "    for r in sycl_ranges:\n",
    "        tmp_above[c][r] = []\n",
    "        tmp_under[c][r] = []\n",
    "        for h in hw:\n",
    "            for alloc_type in [\"device\", \"shared\"]:  \n",
    "                    try:\n",
    "                        tmp_above[c][r].append(above[h][c][alloc_type][r])\n",
    "                        tmp_under[c][r].append(under[h][c][alloc_type][r])\n",
    "                    except:\n",
    "                        pass\n",
    "for c in compilers:\n",
    "    for r in sycl_ranges:\n",
    "        print(f\"{c} - {r} - Above: {np.mean(tmp_above[c][r])}\")\n",
    "        print(f\"{c} - {r} - Under: {np.mean(tmp_under[c][r])}\")\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"For each range, how many times is above the baseline\")\n",
    "tmp_above = dict()\n",
    "tmp_under = dict()\n",
    "for r in sycl_ranges:\n",
    "    tmp_above[r] = []\n",
    "    tmp_under[r] = []\n",
    "    for c in compilers:\n",
    "        for h in hw:\n",
    "            for alloc_type in [\"device\", \"shared\"]:\n",
    "                    try:\n",
    "                        tmp_above[r].append(above[h][c][alloc_type][r])\n",
    "                        tmp_under[r].append(under[h][c][alloc_type][r])\n",
    "                    except:\n",
    "                        pass\n",
    "for r in sycl_ranges:\n",
    "    print(f\"{r} - Above: {np.mean(tmp_above[r])}\")\n",
    "    print(f\"{r} - Under: {np.mean(tmp_under[r])}\")\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"For each alloc_type, how manu times is above the baseline\")\n",
    "tmp_above = dict()\n",
    "tmp_under = dict()\n",
    "for alloc_type in [\"device\", \"shared\"]:\n",
    "    tmp_above[alloc_type] = []\n",
    "    tmp_under[alloc_type] = []\n",
    "    for c in compilers:\n",
    "        for h in hw:\n",
    "            for r in sycl_ranges:\n",
    "                    try:\n",
    "                        tmp_above[alloc_type].append(above[h][c][alloc_type][r])\n",
    "                        tmp_under[alloc_type].append(under[h][c][alloc_type][r])\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "for alloc_type in [\"device\", \"shared\"]:\n",
    "    print(f\"{alloc_type} - Above: {np.mean(tmp_above[alloc_type])}\")\n",
    "    print(f\"{alloc_type} - Under: {np.mean(tmp_under[alloc_type])}\")\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"For each alloc_type and compiler, how many times is above the baseline\")\n",
    "tmp_above = dict()\n",
    "tmp_under = dict()\n",
    "for alloc_type in [\"device\", \"shared\"]:\n",
    "    tmp_above[alloc_type] = dict()\n",
    "    tmp_under[alloc_type] = dict()\n",
    "    for c in compilers:\n",
    "        tmp_above[alloc_type][c] = []\n",
    "        tmp_under[alloc_type][c] = []\n",
    "        for h in hw:\n",
    "            for r in sycl_ranges:\n",
    "                    try:\n",
    "                        tmp_above[alloc_type][c].append(above[h][c][alloc_type][r])\n",
    "                        tmp_under[alloc_type][c].append(under[h][c][alloc_type][r])\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "for alloc_type in [\"device\", \"shared\"]:\n",
    "    for c in compilers:\n",
    "        print(f\"{alloc_type} - {c} - Above: {np.mean(tmp_above[alloc_type][c])}\")\n",
    "        print(f\"{alloc_type} - {c} - Under: {np.mean(tmp_under[alloc_type][c])}\")\n",
    "        \n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"For each alloc_type and hardware, how many times is above the baseline\")\n",
    "tmp_above = dict()\n",
    "tmp_under = dict()\n",
    "for alloc_type in [\"device\", \"shared\"]:\n",
    "    tmp_above[alloc_type] = dict()\n",
    "    tmp_under[alloc_type] = dict()\n",
    "    for h in hw:\n",
    "        tmp_above[alloc_type][h] = []\n",
    "        tmp_under[alloc_type][h] = []\n",
    "        for c in compilers:\n",
    "            for r in sycl_ranges:\n",
    "                    try:\n",
    "                        tmp_above[alloc_type][h].append(above[h][c][alloc_type][r])\n",
    "                        tmp_under[alloc_type][h].append(under[h][c][alloc_type][r])\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "for alloc_type in [\"device\", \"shared\"]:\n",
    "    for h in hw:\n",
    "        print(f\"{alloc_type} - {h} - Above: {np.mean(tmp_above[alloc_type][h])}\")\n",
    "        print(f\"{alloc_type} - {h} - Under: {np.mean(tmp_under[alloc_type][h])}\")\n",
    "\n",
    "\n",
    "# print(\"\\n\")\n",
    "# print(\"For each compiler and alloc_type, the ratio between range and ndrange mlups on NVIDIA hardware\")\n",
    "# for c in compilers:\n",
    "#     for alloc_type in [\"device\", \"shared\"]:\n",
    "#         range_tmp = sycl_csv[(sycl_csv[\"hw\"] == \"NVIDIA\") & (sycl_csv[\"parallelism\"] == c) & (sycl_csv[\"range\"] == \"range\") & (sycl_csv[\"alloc_type\"] == alloc_type)]\n",
    "#         ndrange_tmp = sycl_csv[(sycl_csv[\"hw\"] == \"NVIDIA\") & (sycl_csv[\"parallelism\"] == c) & (sycl_csv[\"range\"] == \"ndrange\") & (sycl_csv[\"alloc_type\"] == alloc_type)]\n",
    "#         print(f\"{c} - {alloc_type}: {range_tmp['mlups'].mean() / ndrange_tmp['mlups'].mean()}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"For each hardware,  compiler, alloc_type, the ratio between range and ndrange mlups\")\n",
    "for h in hw:\n",
    "    for c in compilers:\n",
    "        for alloc_type in [\"device\", \"shared\"]:\n",
    "            range_tmp = sycl_csv[(sycl_csv[\"hw\"] == h) & (sycl_csv[\"parallelism\"] == c) & (sycl_csv[\"range\"] == \"range\") & (sycl_csv[\"alloc_type\"] == alloc_type)]\n",
    "            ndrange_tmp = sycl_csv[(sycl_csv[\"hw\"] == h) & (sycl_csv[\"parallelism\"] == c) & (sycl_csv[\"range\"] == \"ndrange\") & (sycl_csv[\"alloc_type\"] == alloc_type)]\n",
    "            print(f\"{h} - {c} - {alloc_type}: {range_tmp['mlups'].mean() / ndrange_tmp['mlups'].mean()}\")\n",
    "\n",
    "# print(\"\\n\")\n",
    "# print(f\"Range: mean of above: {np.mean(above['range'])}\")\n",
    "# print(f\"Range: mean of under: {np.mean(under['range'])}\")\n",
    "\n",
    "# print(\"\\n\")\n",
    "# print(f\"ND Range: mean of above: {np.mean(above['ndrange'])}\")\n",
    "# print(f\"ND Range: mean of under: {np.mean(under['ndrange'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roofline_2(roofline_data,max_gflops,max_bandwidth,hw,hw_name, rotation_angle, alloc_type, aa_ticks, flop_ticks):\n",
    "    # plt.cla()\n",
    "    # Sample data for performance (GFLOPS), operational intensity (FLOPs/Byte), and memory bandwidth (GB/s)\n",
    "    csv_roofline_data = pd.read_csv(roofline_data)\n",
    "    csv_roofline_data = csv_roofline_data.loc[(csv_roofline_data[\"hw\"] == hw) & (csv_roofline_data[\"alloc_type\"] == alloc_type)]\n",
    "    # fileter mixed1 and mixed2 precision\n",
    "    csv_roofline_data = csv_roofline_data[(csv_roofline_data[\"precision\"] == \"MIXED1\") | (csv_roofline_data[\"precision\"] == \"MIXED2\")]\n",
    "    \n",
    "    balance_point = max_gflops / max_bandwidth\n",
    "    \n",
    "    \n",
    "    # bandwidth_x = np.linspace(1, balance_point)\n",
    "    # bandwidth_y = np.linspace(1, max_gflops)\n",
    "\n",
    "    bandwidth_x = np.linspace(aa_ticks[0], balance_point)\n",
    "    bandwidth_y = [max_bandwidth * x for x in bandwidth_x]\n",
    "    \n",
    "\n",
    "    flops_y = [max_gflops, max_gflops] \n",
    "    flops_x = [balance_point, aa_ticks[-1]]\n",
    "    # Set up the plot using Seaborn\n",
    "    # sns.reset_defaults()\n",
    "    # sns.set_style('ticks',{'axes.grid' : True})\n",
    "    # sns.set_theme(style=\"white\")\n",
    "    # sns.set_context(\"paper\")\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    plot = sns.lineplot(x=bandwidth_x, y=bandwidth_y, label=f'{hw_name} Bandwidth',linestyle='dashed',legend=False, color=\"royalblue\")\n",
    "    plot = sns.lineplot(x=flops_x, y=flops_y, label=f'{hw_name} TFLOPs', linestyle='dashed', legend=False, color=\"firebrick\")\n",
    "    # Palette: palette=sns.color_palette([\"forestgreen\",\"mediumpurple\"],as_cmap=True)\n",
    "    # rename dpcpp to Intel DPC++\n",
    "    csv_roofline_data[\"implementation\"] = csv_roofline_data[\"implementation\"].str.replace(\"dpcpp\", \"Intel DPC++\")\n",
    "    plot = sns.scatterplot(data=csv_roofline_data, x='AI', y='GFLOPS',hue='precision',style='implementation',s=70, legend=\"brief\"\n",
    "                           , style_order=[\"AdaptiveCpp + range\", \"Intel DPC++ + range\", \"AdaptiveCpp + ndrange\", \"Intel DPC++ + ndrange\"])\n",
    "    handles,labels = plot.get_legend_handles_labels()\n",
    "    handles = handles[2:]\n",
    "    labels  = labels[2:]\n",
    "    # Put legend outside the plot\n",
    "    plot.legend(handles,labels,loc=\"lower right\", markerscale=1.2, ncol=1, frameon=True,fancybox=True, shadow=True, \n",
    "                facecolor=\"White\", prop = {\"size\" : 8.5})\n",
    "    # plt.legend(h[2:],l[2:],bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    # plt.show(g)\n",
    "    plot.set(xscale='log', yscale='log')\n",
    "    plot.set(yticks=flop_ticks, xticks=aa_ticks, yticklabels=flop_ticks, xticklabels=aa_ticks)\n",
    "    # start the x axis at 0.1\n",
    "    plot.set_xlim(left=aa_ticks[0])\n",
    "\n",
    "    bandwidth_color = plot.get_lines()[0].get_color()\n",
    "    flops_color = plot.get_lines()[1].get_color()\n",
    "    # Flop line text\n",
    "    flop_text_x_pos = dict({\n",
    "        \"NVIDIA V100S\": 0.2,\n",
    "        \"Intel Max 1100\": 0.39,\n",
    "        \"AMD MI100\": 0.25\n",
    "    })\n",
    "    plot.text(x=balance_point - flop_text_x_pos[hw]  * balance_point, y=(max_gflops + 300),\n",
    "              s=f\"FP64: {max_gflops / 1000} TF/s\", color=flops_color, fontsize=13)\n",
    "    # Bandwidth line text\n",
    "    m = (bandwidth_y[1] - bandwidth_y[0]) / (bandwidth_x[1] - bandwidth_x[0])\n",
    "    y_bandwidth = lambda x: m*(x - bandwidth_x[1]) + bandwidth_y[1]\n",
    "    plot.text(x=aa_ticks[1],y=aa_ticks[1]*max_bandwidth + 1,s=f\"{hw_name} HBM2 BW: {max_bandwidth / 1000} TB/s\",\n",
    "              color=bandwidth_color, rotation=rotation_angle, rotation_mode='anchor', fontsize=13)\n",
    "    # plot.text(x=10**0.3 - 0.2, y=10**1.05 ,s=f\"{hw_name} HBM2 BW: {max_bandwidth / 1000} TB/s\", color=bandwidth_color, rotation=rotation_angle, rotation_mode='anchor')\n",
    "    # Add labels and title\n",
    "    # Increase xlabel and ylabel font size\n",
    "    plt.xlabel('Arithmetic Intensity (FLOPs/Byte)', fontsize=13)\n",
    "    plt.ylabel('FLOP-rate (GF/S)', fontsize=13)\n",
    "    \n",
    "    \n",
    "    # Plot axis ticks\n",
    "    for thick in aa_ticks:\n",
    "        plot = plt.axvline(x=thick, color='gray', linestyle='-', linewidth=0.5)\n",
    "    for thick in flop_ticks:\n",
    "        plot = plt.axhline(y=thick, color='gray', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    plt.savefig(f\"plots/{hw_name}_{alloc_type}_roofline.pdf\", bbox_inches='tight')\n",
    "\n",
    "aa_ticks=[0.4, 0.7, 1,2, 4, 7, 10]\n",
    "# flop_ticks=[40, 70, 100, 400, 700, 1000, 4000, 7000, 12000]\n",
    "flop_ticks=[200, 400, 700, 1000, 4000, 7000, 13000]\n",
    "\n",
    "max_gflops = 6300 #GFLOPs\n",
    "max_bandwidth = 1100  # GB/s, replace with the actual memory bandwidth of your system\n",
    "rotation_angle = 27\n",
    "alloc_type = \"device\"\n",
    "plot_roofline_2(\"./roofline_data.csv\", max_gflops, max_bandwidth, \"NVIDIA V100S\", \"V100S\", rotation_angle, alloc_type, aa_ticks, flop_ticks)\n",
    "alloc_type = \"shared\"\n",
    "plot_roofline_2(\"./roofline_data.csv\", max_gflops, max_bandwidth, \"NVIDIA V100S\", \"V100S\", rotation_angle, alloc_type, aa_ticks, flop_ticks)\n",
    "\n",
    "aa_ticks=[1,2, 4, 7, 10, 20]\n",
    "flop_ticks=[700, 1000, 4000, 7000, 13000]\n",
    "\n",
    "max_gflops = 10500 #GFLOPs\n",
    "max_bandwidth = 890  # GB/s, replace with the actual memory bandwidth of your system\n",
    "rotation_angle = 36\n",
    "alloc_type = \"device\"\n",
    "plot_roofline_2(\"./roofline_data.csv\", max_gflops, max_bandwidth, \"AMD MI100\", \"MI100\", rotation_angle, alloc_type, aa_ticks, flop_ticks)\n",
    "\n",
    "aa_ticks=[0.4, 0.7, 1,2, 4, 7, 10, 20]\n",
    "flop_ticks=[200, 400, 700, 1000, 4000, 7000, 13000]\n",
    "\n",
    "max_gflops = 9150 #GFLOPs\n",
    "max_bandwidth = 800  # GB/s, replace with the actual memory bandwidth of your system\n",
    "rotation_angle = 33\n",
    "alloc_type = \"device\"\n",
    "plot_roofline_2(\"./roofline_data.csv\", max_gflops, max_bandwidth, \"Intel Max 1100\", \"Intel Max 1100\", rotation_angle, alloc_type, aa_ticks, flop_ticks)\n",
    "alloc_type = \"shared\"\n",
    "plot_roofline_2(\"./roofline_data.csv\", max_gflops, max_bandwidth, \"Intel Max 1100\", \"Intel Max 1100\", rotation_angle, alloc_type, aa_ticks, flop_ticks)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "csv = pd.read_csv(\"roofline_data.csv\")\n",
    "\n",
    "# Performance portability \n",
    "def get_pp(csv, hardware):\n",
    "    res = dict()\n",
    "    hw_subset = csv[csv[\"hw\"] == hardware]\n",
    "    res[\"best\"] = hw_subset[\"FLOP/Peak\"].max() / 100\n",
    "    for precision in hw_subset[\"precision\"].unique():\n",
    "        res[precision] = dict()\n",
    "        precision_subset = hw_subset[hw_subset[\"precision\"] == precision]\n",
    "        res[precision][\"max\"] = precision_subset[\"FLOP/Peak\"].max() / 100 \n",
    "        for range_type in [\"range\", \"ndrange\"]:\n",
    "            range_subset = precision_subset[precision_subset[\"range\"] == range_type]\n",
    "            res[precision][range_type] = dict()\n",
    "            res[precision][range_type][\"max\"] = range_subset[\"FLOP/Peak\"].max() / 100\n",
    "            for alloc in [\"device\", \"shared\"]:\n",
    "                alloc_subset = range_subset[range_subset[\"alloc_type\"] == alloc]\n",
    "                res[precision][range_type][alloc] = alloc_subset[\"FLOP/Peak\"].max() / 100\n",
    "    return res\n",
    "\n",
    "nvidia = get_pp(csv, \"NVIDIA V100S\")\n",
    "amd = get_pp(csv, \"AMD MI100\")\n",
    "intel = get_pp(csv, \"Intel Max 1100\")\n",
    "\n",
    "NUM_HW = 3\n",
    "pp = dict()\n",
    "for p in precision:\n",
    "    pp[p] = dict()\n",
    "    pp[p][\"pp metric\"] = 3 / (1 / nvidia[p][\"max\"] + 1 / amd[p][\"max\"] + 1 / intel[p][\"max\"])\n",
    "    for r in sycl_ranges:\n",
    "        pp[p][r] = dict() \n",
    "        pp[p][r][\"pp_metric\"] = 3 / (1 / nvidia[p][r][\"max\"] + 1 / amd[p][r][\"max\"] + 1 / intel[p][r][\"max\"])\n",
    "        for alloc in [\"device\", \"shared\"]:\n",
    "            amd_value = (1 / amd[p][r][alloc])  #Threat amd perf as 0 for shared memory\n",
    "            pp[p][r][alloc] = 3 / (1 / nvidia[p][r][alloc] + amd_value + 1 / intel[p][r][alloc]) \n",
    "\n",
    "    \n",
    "pprint.pp(pp)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
